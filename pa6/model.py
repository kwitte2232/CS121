# CS121 Linear regression
#
# Kristen Witte, kwitte

import numpy as np
from asserts import assert_Xy, assert_Xbeta


#############################
#                           #
#  Our code: DO NOT MODIFY  #
#                           #
#############################


def prepend_ones_column(A):
    '''
    Add a ones column to the left side of an array

    Inputs: 
        A: a numpy array

    Output: a numpy array
    '''
    ones_col = np.ones((A.shape[0], 1))
    return np.hstack([ones_col, A])


def linear_regression(X, y):
    '''
    Compute linear regression. Finds model, beta, that minimizes
    X*beta - Y in a least squared sense.

    Accepts inputs with type array
    Returns beta, which is used only by apply_beta

    Examples
    --------
    >>> X = np.array([[5, 2], [3, 2], [6, 2.1], [7, 3]]) # predictors
    >>> y = np.array([5, 2, 6, 6]) # dependent
    >>> beta = linear_regression(X, y)  # compute the coefficients
    >>> beta
    array([ 1.20104895,  1.41083916, -1.6958042 ])
    >>> apply_beta(beta, X) # apply the function defined by beta
    array([ 4.86363636,  2.04195804,  6.1048951 ,  5.98951049])
    '''
    assert_Xy(X, y, fname='linear_regression')

    X_with_ones = prepend_ones_column(X)

    # Do actual computation
    beta = np.linalg.lstsq(X_with_ones, y)[0]

    return beta


def apply_beta(beta, X):
    '''
    Apply beta, the function generated by linear_regression, to the
    specified values

    Inputs:
        model: beta as returned by linear_regression
        Xs: 2D array of floats

    Returns:
        result of applying beta to the data, as an array.

        Given:
            beta = array([B0, B1, B2,...BK])
            Xs = array([[x11, x12, ..., x0K],
                        [x21, x22, ..., x1K],
                        ...
                        [xN1, xN2, ..., xNK]])

            result will be:
            array([B0+B1*x11+B2*x12+...+BK*x1K,
                   B0+B1*x21+B2*x22+...+BK*x2K,
                   ...
                   B0+B1*xN1+B2*xN2+...+BK*xNK])
    '''
    assert_Xbeta(X, beta, fname='apply_beta')

    # Add a column of ones
    X_incl_ones = prepend_ones_column(X)

    # Calculate X*beta
    yhat = np.dot(X_incl_ones, beta)
    return yhat


def read_file(filename):
    '''
    Read data from the specified file.  Split the lines and convert
    float strings into floats.  Assumes the first row contains labels
    for the columns.

    Inputs:
      filename: name of the file to be read

    Returns:
      (list of strings, 2D array)
    '''
    with open(filename) as f:
        labels = f.readline().strip().split(',')
        data = np.loadtxt(f, delimiter=',', dtype=np.float64)
        return labels, data


###############
#             #
#  Your code  #
#             #
###############

def calculate_R2(curr_yhats, y_test, y_mean):
    '''
    Compute the R2 value for given data

    Inputs:
        curr_yhats = numpy array derived from apply_beta
        y_test: numpy array for the dependent variable. Either from 
            training.csv or testing.csv depending on find_R2
        y_mean: average of y* derived from either training.csv 
            or testing.csv depending on find_R2 

    Returns:
        r2: R^2 value as a float
    '''

    numerator = []
    denominator = []

    for i, yn in enumerate(y_test):
        yhat = curr_yhats[i]
        top = (yn - yhat)**2
        bottom = (yn - y_mean)**2
        numerator.append(top)
        denominator.append(bottom)

    sum_numerator = sum(numerator)
    sum_denominator = sum(denominator)
    r2 = 1 - (sum_numerator/sum_denominator)

    return r2

def find_R2(x_train, y_train, y_mean, x_test = None, y_test = None):
    '''
    Find the R2 value for given data using linear_regression and apply_beta

    Inputs:
        x_train: independent variable data from training.csv
        y_train: dependent variab data from training.csv
        y_mean: average of y* (default from training.csv or if 
            x_test is not None, testing.csv)
            Optional Inputs:
                x_test: independent variable data from testing.csv
                y_test: dependent variab data from testing.csv

    Returns:
        r2: R^2 value as a float
    '''

    if x_test is not None:
        beta = linear_regression(x_train, y_train)
        yhats = apply_beta(beta, x_test)
        r2 = calculate_R2(yhats, y_test, y_mean)
    else:
        beta = linear_regression(x_train, y_train)
        yhats = apply_beta(beta, x_train)
        r2 = calculate_R2(yhats, y_train, y_mean)
    return r2

def build_K_arrays(dex, cat, temp_arrays, r2s, base_category, remaining,
    base_num_rows, y_train, y_mean, temp_train_data = None, y_test = None):
    '''
    Builds numpy arrays of K categories. Used in a for loop in
        get_R2 "Arbitrary"

    Inputs:
        dex: current index
        cat: current category
        temp_arrays: empty dictionary to store numpy arrays for K categories
        r2s: empty dicitonary to store R2s for K categories
        base_category: numpy array for K = 1
        remaing: numpy array for the reamining data after removing 
            base_category data
        base_num_rows: numer of rows in base_category
        y_train: numpy array for the y data from training.csv
        y_mean: average of the y values for either the training.csv
            or the testing.csv (if y_test is not None)
        Optional inputs:
            temp_train_data: dictionary storing the training numpy array
                for K categories
            y_test: numpy array for the y data from testing.csv

    Returns:
        r2s: filled dictionary of R2s for K categories
        temp_arrays: filled dictionary of numpy arrays for K categories
        If y_test is None:
            temp_data: numpy array for K categories (solely for training data)
    '''

    temp_data = np.empty([base_num_rows, 0])
    temp_data = np.append(temp_data, 
        base_category, axis = 1)
    additional_category = remaining[:,[dex]]
    temp_data = np.append(temp_data, 
        additional_category, axis = 1)
    temp_arrays[cat] = temp_data

    if y_test is None:
        r2 = find_R2(temp_data, y_train, y_mean)
    else:
        r2 = find_R2(temp_train_data, y_train, y_mean, temp_data, y_test)
    
    r2s[cat] = r2

    if y_test is None:
        return r2s, temp_arrays, temp_data
    else:
        return r2s, temp_arrays


def ratio_less_than_threshold(all_variables, compiled_data, threshold):
    '''
    Determines if the increase in K R^2 from K-1 R^2 is greater than threshold

    Inputs:
        all_variables: a list of all the current column categories
        compiled_data: dictionary of the categories and their R^2 values
        threshold: float

    Returns:
        Boolean
        If Boolean is True, also returns the K-1 category
    '''

    assert len(list(compiled_data.keys())) >= 2
    assert threshold is not None

    k_categories = ','.join(all_variables)
    k_1_variables = all_variables[:-1]
    k_subtract_1_categories = ','.join(k_1_variables)

    k_r2 = compiled_data[k_categories]
    k_subtract_1_r2 = compiled_data[k_subtract_1_categories]

    percent_increase = (k_r2/k_subtract_1_r2) - 1

    if percent_increase < threshold:
        return True, k_subtract_1_categories
    else:
        return False, None


def get_R2(col_names, data_train, num_vars, data_test = None, 
    threshold = None):
    '''
    Returns the R2 squared value(s) using linear regression

    Inputs:
        col_names: a list of the column names from the read in data_test
        data_train: a numpy array of the data from training.csv 
        num_vars: string indicating amount of data to include 
            in the linear regression
            Options:"Single": R^2 value for each column 
                    "Multi":  R^2 value for all columns
                    "BiVar":  R^2 value for pairs of columns
                    "Arbitrary": R^2 value for K columns
        Optional Inputs:
            *Only used when num_vars is "Arbitrary"*
            data_test: a numpy array of the data from testing.csv
            threshold: minimum percent that R^2 must increase by with
                increasing K

    Returns:
        Options:"Single": a list of the R^2 values 
                "Multi":  a list of the R^2 value (single element)
                "BiVar":  two single element lists. One of the Category 
                          pair with the highest R^2. One of the R^2 value
                          for that pair.
                "Arbitrary": a dictionary of 1 <= K <= N categories and 
                        the corresponding R^2 value for K.
                        If threshold is not None: a second dictionary with the 
                        K-1 categories and the corresponding R^2 value such that
                        the percent increase of K R^2 to K-1 R^2 is less than
                        threshold.
    '''

    total_cols = len(col_names)
    y_train = data_train[:, (total_cols - 1)]
    all_training = data_train[: , 0:total_cols - 1]

    y_mean = (y_train.sum()/len(y_train))
    
    if data_test is not None:
        y_test = data_test[:, (total_cols - 1)]
        all_test = data_test[: , 0:total_cols - 1]
        y_mean = (y_test.sum()/len(y_test))
        
    num_categories = total_cols - 1

    r2_values = []

    if num_vars == "Single":
        for i in range(num_categories):
            curr_train_category = all_training[:,[i]] 
            if data_test is not None:
                curr_test_category = all_test[:,[i]]
                r2 = find_R2(curr_train_category, y_train, 
                    y_mean, curr_test_category, y_test)
            else: r2 = find_R2(curr_train_category, y_train, 
                    y_mean)
            r2_values.append(r2)
        return r2_values
    
    elif num_vars == "Multi":
        r2 = find_R2(all_training, y_train, y_mean)
        r2_values.append(r2)
        return r2_values
    
    elif num_vars == "BiVar":
        paired_r2 = {}
        for i in range(num_categories):
            base_category = all_training[:,[i]]
            for j in range(i+1, num_categories):
                paired_category = all_training[:,[j]]
                bivar_data = np.concatenate((base_category, 
                    paired_category), axis = 1)
                r2 = find_R2(bivar_data, y_train, y_mean)
                pair = col_names[i] + ":" + col_names[j]
                paired_r2[pair] = r2

        highest_r2 = 0
        for pair in paired_r2:
            r2 = paired_r2[pair]
            if r2 >= highest_r2:
                highest_r2 = r2
                highest_pair = [pair]

        r2_values.append(highest_r2)

        return highest_pair, r2_values

    elif num_vars == "Arbitrary":

        compiled_data = {}

        if data_test is not None:
            single_test_r2s = get_R2(col_names, data_train, 
                "Single", data_test)
        
        single_r2s = get_R2(col_names, data_train, "Single")
        highest_r2 = 0
        for i, r2 in enumerate(single_r2s):
            if r2 >= highest_r2:
                highest_r2 = r2
                highest_category = col_names[i]
                index_highest_category = i
        
        all_variables = [highest_category]
        category_names = highest_category
        
        if data_test is not None:
            compiled_data[category_names] = single_test_r2s[index_highest_category]
        else:
            compiled_data[category_names] = single_r2s[index_highest_category]

        base_train_category = all_training[:,[index_highest_category]]
        base_train_rows = len(base_train_category)
        if data_test is not None:
            base_test_category = all_test[:,[index_highest_category]]
            base_test_rows = len(base_test_category)

        remaining_training = np.delete(all_training, 
            [index_highest_category], axis = 1)
        if data_test is not None:
            remaining_test = np.delete(all_test, 
                [index_highest_category], axis = 1)

        remaining_cols = [x for x in col_names if x != highest_category]
        remaining_cols.pop() #remove the totals column
        num_remaining = len(remaining_cols)
        
        best = {} #for thresholding

        for i in range(num_remaining):
            temp_train_arrays = {} #temp arrays
            temp_test_arrays = {}
            train_r2s = {} #r2s
            test_r2s = {}
            for j, category in enumerate(remaining_cols):
                if category not in all_variables:
                    train_r2s, temp_train_arrays, temp_train_data = build_K_arrays(j,
                        category, temp_train_arrays, train_r2s, base_train_category,
                        remaining_training, base_train_rows, y_train, y_mean)
                    
                    if data_test is not None:
                        test_r2s, temp_test_arrays = build_K_arrays(j, category, 
                            temp_test_arrays, test_r2s, base_test_category, remaining_test,
                            base_test_rows, y_train, y_mean, temp_train_data, y_test)
                        
            highest_r2 = 0
            for category in train_r2s:
                current_r2 = train_r2s[category]
                if current_r2 >= highest_r2:
                    highest_r2 = current_r2
                    highest_category = category #From the train data
                    base_train_category = temp_train_arrays[highest_category]
                    if data_test is not None:
                        base_test_category = temp_test_arrays[highest_category]

            all_variables.append(highest_category)

            category_names = ','.join(all_variables)
            if data_test is not None:
                compiled_data[category_names] = test_r2s[highest_category]
            else:
                 compiled_data[category_names] = train_r2s[highest_category]
            if threshold != None:
                x, final_key = ratio_less_than_threshold(all_variables, 
                    compiled_data, threshold)

                if not best:
                    if x:
                        best[final_key] = compiled_data[final_key]
        
        if threshold != None:
            return compiled_data, best
        return compiled_data


def print_dict_data(d):
    '''
    Prints out the info from a dictionary in an easy to read format

    Inputs:
        d: dictionary

    Returns:
        prints out data from dictionary.
    '''

    for key in d:
        print(key + " : " + str(d[key]))


def make_table(r2_values, names):
    '''
    Makes a table for the provided r2_values and the k_categories

    Inputs:
        r2_values: list of R2 values
        names: list of names
        **indices of names and r2_values must match

    Returns:
        prints out a nicely formatted table.
    '''

    COLUMN_WIDTH = 18
    COLUMN_SEP = "|"    

    names.insert(0, "Category")
    r2_values.insert(0, "R2")

    table = []
    for i, name in enumerate(names):
        insert = []
        insert = make_column(name, insert, COLUMN_WIDTH, COLUMN_SEP)
        insert = make_column(r2_values[i], insert, COLUMN_WIDTH, COLUMN_SEP)
        insert.append('\n')
        table.append(insert)

    for row in table:
        line = ''.join(row)
        print(line)


def make_column(current_input, insert, COLUMN_WIDTH, COLUMN_SEP):
    '''
    Makes a column insert for table

    Inputs:
        current_input: a the category name or r2 values
        insert: an empty list
        COLUMN_WIDTH: integer
        COLUMN_SEP: string

    Returns:
        insert: a single element list. 
            Element is the string for that column
    '''

    inp = current_input
    t = type(inp)
    if t == np.float64 or t == int:
        inp = str(inp)
    curr_characters = len(inp)
    space = [' ']
    diff = COLUMN_WIDTH - curr_characters
    if diff < 0:
        num_characters = abs(diff+1)
        inp = inp[:diff]
    else:
        while len(space) < diff:
            space.append(' ')
    spaces = ''.join(space)
    insert.append(inp)
    insert.append(spaces)
    insert.append(COLUMN_SEP)

    return insert
